{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Project goals translate apps faster : Pimp my Trad integrates with git to edit your files directly prevent mistakes and allow automation : avoid manually editing translation files ease communication with translation agencies by exporting relevant data to a suitable format Usage Importing and setting up keysets To get started, import a project from a git repository (in the future, other VCS might be supported). By browsing to the \"Fichiers\" tab, you may then create a keyset . A keyset groups files that refer to the same translation keys together. One such file might look like that. GREET_VISITOR=Welcome While the corresponding file in the same keyset but for another language might read as follows. GREET_VISITOR=Bienvenue Beside .properties files, .json files are supported. Support for other formats can easily be added (see sncf.oui.pmt.domain.keyset.MapEncoder ). Managing keys Back to the main screen (\"Cl\u00e9s\" tab), you should now see your translation keys as well as their value in the default language (French). Each key has a completion state : TODO , INPROGRESS , DONE (and CONFLICT ). By clicking one of the state tags on the right, you may quickly filter which keys need work -- ie which keys have missing ( TODO ) or temporary translations. You may also use the search bar to quickly find a key. Most of the time, the state is inferred (for instance, if a key is empty for a given language, it probably is TODO ). However, you may add a tag to a translation to give a hint about the key state. For instance, the INPROGRESS state has no special meaning; you could use it to indicate that you have requested a translation for that particular key. Adding keys and languages From the sidebar, you may add new keys as well as new languages. Both these features let you select which project and keyset should be modified. Pimp my Trad will try to guess a fitting name for new files when adding a new language. Version control By hitting \"Synchroniser\", the repository will receive your updated translations (and you will receive updates as well). Since Pimp my Trad uses Git, it might run into conflicts; should this happen, you will be warned and relevant keys will have the CONFLICT state. You will be given the opportunity to fix conflicts from the interface before clicking \"Synchroniser\" again. Planned features The tool was built to ease our translation process. One essential feature that will come later is the ability to export and import keys in a format that is suitable to communicate with our translation agency. The INPROGRESS state will be used to indicate that an export has been made. Support for more languages (and language-region combinations) and more file formats is planned, depending on our needs. The former could be implemented through configuration files. The search bar has an extremely simple filtering behaviour which has to be changed.","title":"Home"},{"location":"#project-goals","text":"translate apps faster : Pimp my Trad integrates with git to edit your files directly prevent mistakes and allow automation : avoid manually editing translation files ease communication with translation agencies by exporting relevant data to a suitable format","title":"Project goals"},{"location":"#usage","text":"","title":"Usage"},{"location":"#importing-and-setting-up-keysets","text":"To get started, import a project from a git repository (in the future, other VCS might be supported). By browsing to the \"Fichiers\" tab, you may then create a keyset . A keyset groups files that refer to the same translation keys together. One such file might look like that. GREET_VISITOR=Welcome While the corresponding file in the same keyset but for another language might read as follows. GREET_VISITOR=Bienvenue Beside .properties files, .json files are supported. Support for other formats can easily be added (see sncf.oui.pmt.domain.keyset.MapEncoder ).","title":"Importing and setting up keysets"},{"location":"#managing-keys","text":"Back to the main screen (\"Cl\u00e9s\" tab), you should now see your translation keys as well as their value in the default language (French). Each key has a completion state : TODO , INPROGRESS , DONE (and CONFLICT ). By clicking one of the state tags on the right, you may quickly filter which keys need work -- ie which keys have missing ( TODO ) or temporary translations. You may also use the search bar to quickly find a key. Most of the time, the state is inferred (for instance, if a key is empty for a given language, it probably is TODO ). However, you may add a tag to a translation to give a hint about the key state. For instance, the INPROGRESS state has no special meaning; you could use it to indicate that you have requested a translation for that particular key.","title":"Managing keys"},{"location":"#adding-keys-and-languages","text":"From the sidebar, you may add new keys as well as new languages. Both these features let you select which project and keyset should be modified. Pimp my Trad will try to guess a fitting name for new files when adding a new language.","title":"Adding keys and languages"},{"location":"#version-control","text":"By hitting \"Synchroniser\", the repository will receive your updated translations (and you will receive updates as well). Since Pimp my Trad uses Git, it might run into conflicts; should this happen, you will be warned and relevant keys will have the CONFLICT state. You will be given the opportunity to fix conflicts from the interface before clicking \"Synchroniser\" again.","title":"Version control"},{"location":"#planned-features","text":"The tool was built to ease our translation process. One essential feature that will come later is the ability to export and import keys in a format that is suitable to communicate with our translation agency. The INPROGRESS state will be used to indicate that an export has been made. Support for more languages (and language-region combinations) and more file formats is planned, depending on our needs. The former could be implemented through configuration files. The search bar has an extremely simple filtering behaviour which has to be changed.","title":"Planned features"},{"location":"auth/","text":"Authentication Git authentication Pimp my Trad uses basic authentication to push to/pull from repositories. The credentials for this user are specified in the application.yml file for the pimp-my-trad-api module. This means that whatever account is used to push/pull has to have write access to the repositories. It should be a service account that repository owners can add to their repository. API authentication Currently, the chosen authentication method for the API is basic authentication + Active Directory. Keycloak (an OIDC server) was previously used for this task: some code to authenticate with an OIDC server is still available in the main pimp-my-trad-api module. If the auth system is changed, a new implementation of sncf.oui.pmt.infrastructure.AuthenticationDetails might be needed.","title":"Authentication"},{"location":"auth/#authentication","text":"","title":"Authentication"},{"location":"auth/#git-authentication","text":"Pimp my Trad uses basic authentication to push to/pull from repositories. The credentials for this user are specified in the application.yml file for the pimp-my-trad-api module. This means that whatever account is used to push/pull has to have write access to the repositories. It should be a service account that repository owners can add to their repository.","title":"Git authentication"},{"location":"auth/#api-authentication","text":"Currently, the chosen authentication method for the API is basic authentication + Active Directory. Keycloak (an OIDC server) was previously used for this task: some code to authenticate with an OIDC server is still available in the main pimp-my-trad-api module. If the auth system is changed, a new implementation of sncf.oui.pmt.infrastructure.AuthenticationDetails might be needed.","title":"API authentication"},{"location":"dev/","text":"Installation and development Building The backend uses Maven . Just tweak some settings before building (the sample file is mostly empty); currently, the app requires adding Github/Gitlab/etc credentials with write access to the repositories in the configuration file. $ cp back/pimp-my-trad-api/src/main/resources/application.tmpl.yml back/pimp-my-trad-api/src/main/resources/application.yml $ mvn package Alternatively, with Docker: docker run --rm -v \"$PWD/back\":/usr/src/app -v \"$HOME/.m2\":/root/.m2 -v \"$PWD/back/pimp-my-trad-api/target\":/usr/src/app/target -w /usr/src/app maven mvn package To build the frontend, just install the NPM dependencies and run build . $ npm install $ npm run build Again, with Docker: docker run --rm -v \"$PWD/front\":/usr/src/app -v \"$PWD/front/build\":/usr/src/app/build -w /usr/src/app node /bin/bash -c 'npm install && npm run build' Running You may run the project using Docker and docker-compose for ease. A sample docker-compose.yml is included. Don't forget to include a proper configuration file before building, see application-docker.tmpl.yml . $ docker-compose up -d Development During development, just java -jar the fat jar once it has been built. The frontend can be run using npm start . You will also need a Mongo instance running. Testing Maven should run some unit tests automatically. \"Behaviour\" tests are available in the bdd package. A sample docker-compose-test.yml file is included to demonstrate how to run these tests. docker-compose -f docker-compose-test.yml run --use-aliases bdd The bdd module does the following: runs an embedded Jetty server that mocks a Git repository, with basic auth (expecting any username, and \"password\" as the password ) connects to the backend (API) without authentication -- the user is hardcoded to be \"test_user\" when the API runs with the test profile runs tests by calling the API Data will be inserted into your Mongo database but should be removed by the end of the tests.","title":"Installation and development"},{"location":"dev/#installation-and-development","text":"","title":"Installation and development"},{"location":"dev/#building","text":"The backend uses Maven . Just tweak some settings before building (the sample file is mostly empty); currently, the app requires adding Github/Gitlab/etc credentials with write access to the repositories in the configuration file. $ cp back/pimp-my-trad-api/src/main/resources/application.tmpl.yml back/pimp-my-trad-api/src/main/resources/application.yml $ mvn package Alternatively, with Docker: docker run --rm -v \"$PWD/back\":/usr/src/app -v \"$HOME/.m2\":/root/.m2 -v \"$PWD/back/pimp-my-trad-api/target\":/usr/src/app/target -w /usr/src/app maven mvn package To build the frontend, just install the NPM dependencies and run build . $ npm install $ npm run build Again, with Docker: docker run --rm -v \"$PWD/front\":/usr/src/app -v \"$PWD/front/build\":/usr/src/app/build -w /usr/src/app node /bin/bash -c 'npm install && npm run build'","title":"Building"},{"location":"dev/#running","text":"You may run the project using Docker and docker-compose for ease. A sample docker-compose.yml is included. Don't forget to include a proper configuration file before building, see application-docker.tmpl.yml . $ docker-compose up -d","title":"Running"},{"location":"dev/#development","text":"During development, just java -jar the fat jar once it has been built. The frontend can be run using npm start . You will also need a Mongo instance running.","title":"Development"},{"location":"dev/#testing","text":"Maven should run some unit tests automatically. \"Behaviour\" tests are available in the bdd package. A sample docker-compose-test.yml file is included to demonstrate how to run these tests. docker-compose -f docker-compose-test.yml run --use-aliases bdd The bdd module does the following: runs an embedded Jetty server that mocks a Git repository, with basic auth (expecting any username, and \"password\" as the password ) connects to the backend (API) without authentication -- the user is hardcoded to be \"test_user\" when the API runs with the test profile runs tests by calling the API Data will be inserted into your Mongo database but should be removed by the end of the tests.","title":"Testing"},{"location":"doc_func/","text":"API L'API est document\u00e9e par un fichier Swagger (voir repo). Fonctionnalit\u00e9s Visualiser le reste \u00e0 faire A chaque cl\u00e9 est associ\u00e9 un \u00e9tat permettant le filtrage de celle-ci, et une visualition de ce qu'il reste \u00e0 traduire. Un syst\u00e8me de tags permet de modifier cet \u00e9tat. Par exemple : la traduction Contenu d'une cl\u00e9 [TODO] a l'\u00e9tat TODO . L'\u00e9tat de la cl\u00e9 (ensemble des traductions) est l'\u00e9tat le plus \"critique\" parmi les \u00e9tats des traductions : plus critique = TODO > INPROGRESS > DONE = moins critique. Une traduction vide a l'\u00e9tat TODO (et donc la cl\u00e9 associ\u00e9e aussi). Ajout de wordings et langues La modification (ou l'ajout \u2013 l'op\u00e9ration est la m\u00eame) d'un wording est possible. Les fichiers contenant les cl\u00e9s sont modifi\u00e9s. Note : l'ordre des cl\u00e9s n'est pas forc\u00e9ment le m\u00eame dans le fichier final. On peut \u00e9galement ajouter une langue \u00e0 un Keyset. Cela ne fait qu'ajouter un nouveau fichier comprenant les cl\u00e9s du Keyset cibl\u00e9, et leur associe des traductions vides : wording.hello= . Traduire imm\u00e9diatemment Il est possible de traduire directement une cl\u00e9 \u00e0 l'aide d'un service externe (Google Translate). Comme pr\u00e9c\u00e9demment, les fichier sont directement \u00e9crits. Un tag TODO est ajout\u00e9 \u00e0 la traduction obtenue. Importer et exporter des traductions L'export rassemble les traductions fran\u00e7aises de toutes les cl\u00e9s TODO ou INPROGRESS dans un fichier CSV (une seule colonne). La correspondance entre chaque ligne et ses informations techniques (projet, keyset, identifiant de cl\u00e9) est sauvegard\u00e9e en base, et ces donn\u00e9es peuvent \u00eatre r\u00e9cup\u00e9r\u00e9es \u00e0 l'aide du num\u00e9ro d'export. L'import modifie directement les fichiers \u00e9galement. Centraliser les modifications Les modifications des fichiers sont centralis\u00e9es en passant par un syst\u00e8me de versionnement comme Git. Cela se traduit par la fonctionnalit\u00e9 de synchronisation (cf. Swagger). Deux cas de figure : si le rappatriement des changements distants \u00e9chouant, des cl\u00e9s passent dans l'\u00e9tat CONFLICT . Une fois les conflits r\u00e9solus en modifiant les cl\u00e9s en conflit, il est possible de synchroniser \u00e0 nouveau. Sinon, les changements locaux sont partag\u00e9s (et les changements distants sont rappatri\u00e9s).","title":"Documentation fonctionnelle"},{"location":"doc_func/#api","text":"L'API est document\u00e9e par un fichier Swagger (voir repo).","title":"API"},{"location":"doc_func/#fonctionnalites","text":"","title":"Fonctionnalit\u00e9s"},{"location":"doc_func/#visualiser-le-reste-a-faire","text":"A chaque cl\u00e9 est associ\u00e9 un \u00e9tat permettant le filtrage de celle-ci, et une visualition de ce qu'il reste \u00e0 traduire. Un syst\u00e8me de tags permet de modifier cet \u00e9tat. Par exemple : la traduction Contenu d'une cl\u00e9 [TODO] a l'\u00e9tat TODO . L'\u00e9tat de la cl\u00e9 (ensemble des traductions) est l'\u00e9tat le plus \"critique\" parmi les \u00e9tats des traductions : plus critique = TODO > INPROGRESS > DONE = moins critique. Une traduction vide a l'\u00e9tat TODO (et donc la cl\u00e9 associ\u00e9e aussi).","title":"Visualiser le reste \u00e0 faire"},{"location":"doc_func/#ajout-de-wordings-et-langues","text":"La modification (ou l'ajout \u2013 l'op\u00e9ration est la m\u00eame) d'un wording est possible. Les fichiers contenant les cl\u00e9s sont modifi\u00e9s. Note : l'ordre des cl\u00e9s n'est pas forc\u00e9ment le m\u00eame dans le fichier final. On peut \u00e9galement ajouter une langue \u00e0 un Keyset. Cela ne fait qu'ajouter un nouveau fichier comprenant les cl\u00e9s du Keyset cibl\u00e9, et leur associe des traductions vides : wording.hello= .","title":"Ajout de wordings et langues"},{"location":"doc_func/#traduire-immediatemment","text":"Il est possible de traduire directement une cl\u00e9 \u00e0 l'aide d'un service externe (Google Translate). Comme pr\u00e9c\u00e9demment, les fichier sont directement \u00e9crits. Un tag TODO est ajout\u00e9 \u00e0 la traduction obtenue.","title":"Traduire imm\u00e9diatemment"},{"location":"doc_func/#importer-et-exporter-des-traductions","text":"L'export rassemble les traductions fran\u00e7aises de toutes les cl\u00e9s TODO ou INPROGRESS dans un fichier CSV (une seule colonne). La correspondance entre chaque ligne et ses informations techniques (projet, keyset, identifiant de cl\u00e9) est sauvegard\u00e9e en base, et ces donn\u00e9es peuvent \u00eatre r\u00e9cup\u00e9r\u00e9es \u00e0 l'aide du num\u00e9ro d'export. L'import modifie directement les fichiers \u00e9galement.","title":"Importer et exporter des traductions"},{"location":"doc_func/#centraliser-les-modifications","text":"Les modifications des fichiers sont centralis\u00e9es en passant par un syst\u00e8me de versionnement comme Git. Cela se traduit par la fonctionnalit\u00e9 de synchronisation (cf. Swagger). Deux cas de figure : si le rappatriement des changements distants \u00e9chouant, des cl\u00e9s passent dans l'\u00e9tat CONFLICT . Une fois les conflits r\u00e9solus en modifiant les cl\u00e9s en conflit, il est possible de synchroniser \u00e0 nouveau. Sinon, les changements locaux sont partag\u00e9s (et les changements distants sont rappatri\u00e9s).","title":"Centraliser les modifications"},{"location":"doc_tech/","text":"Architecture logique L'API utilise Mongo pour stocker des m\u00e9tadonn\u00e9es uniquement. Les vraies donn\u00e9es sont lues \u00e0 partir de repo clon\u00e9s via l'app. L'API interragit avec Git, mais d'autres VCS devraient pouvoir \u00eatre impl\u00e9ment\u00e9. Concepts C\u00f4t\u00e9 base de donn\u00e9es, on ne garde que les m\u00e9tadonn\u00e9es des Project/Keyset/Key. Les objects Project , Keyset et Key sont fournis en r\u00e9ponse par l'API Rest (cf Swagger). { \"state\": \"Conflict\", \"translations\": { \"FR\": [ \"Annuler\" ], \"DE\": [ \"stornieren\" ], \"ES\": [ \"Anular\" ], \"EN\": [ \"Cancel\", \"Something else\" ] } } Une Key est la donn\u00e9e d'un \u00e9tat de cl\u00e9 (\u00e0 traduire = TODO , traduction demand\u00e9e = INPROGRESS ...) et de traductions (correspondance langue et liste de cha\u00eenes \u2013 la liste comporte une valeur en cas g\u00e9n\u00e9ral, et deux quand un conflit survient). Un Keyset agr\u00e8ge un ensemble de cl\u00e9 ensemble, et fournit quelques donn\u00e9es suppl\u00e9mentaires (nom, id, langages pris en compte...). Finalement, un Project agr\u00e8ge divers Keyset . C\u00f4t\u00e9 repr\u00e9sentation interne, ProjectMetadata et KeysetMetadata permettent de reconstruire les entit\u00e9s correspondantes. Le KeysetMetadata donne les chemins des fichiers de traduction qui contiennent les cl\u00e9s d'un Keyset . Par exemple, un fichier va contenir les traductions en anglais et un autre les traductions en allemand, et ce pour les m\u00eames cl\u00e9s techniques. Les exports sont g\u00e9r\u00e9s via deux entit\u00e9s. L'entit\u00e9 ExportDetails contient l'export CSV ainsi que des m\u00e9tadonn\u00e9es (sauv\u00e9es en base) qui permettent de retrouver l'export. Il faut en effet conserver des infos sur l'export (d'o\u00f9 KeySpec notamment qui redonne le \"chemin\" complet vers une cl\u00e9: projet, keyset, identifiant) car l'export ne contient que du texte brute, aucune m\u00e9tadonn\u00e9e. Lecture et \u00e9criture de fichiers avec gestion de conflits Remarque. Ici, on utilise le vocabulaire git ou presque, mais l'abstraction devrait pouvoir s'appliquer \u00e0 d'autres syst\u00e8mes de versionnement. Les \u00e9tapes pour la lecture : (g\u00e9r\u00e9 par FileHandler ) lecture des lignes (fichier \u2192 Flux<String> ) : assur\u00e9 par ConflictingFileHandle ; un drapeau ( ConflictFlag ) indique si l'on veut lire nos lignes ( ConflictFlag.StrictlyOurs ) ou les lignes upstream s'il y a des conflits ( ConflictFlag.StrictlyTheirs ), ou encore les lignes en commun ( ConflictFlag.Solved ), null peut \u00eatre utilis\u00e9 au lieu d'un drapeau s'il n'y a pas de conflit; traduction en dictionnaire ( Flux<String> \u2192 Map<String, String> ) : un MapEncoder \"adapt\u00e9\" (crit\u00e8re : extension du fichier) traduit le flux de lignes en dictionnaire (impl\u00e9ment\u00e9 : json, properties); adaptation : op\u00e9ration de diff au niveau des Maps selon que l'on veuille lire la version upstream ou la notre, d\u00e9tails ci dessous; conversion en Keyset : utilisation de Keyset.fromMaps pour obtenir une entit\u00e9 du domaine pour traitement fonctionnel. Pour l'\u00e9criture, c'est l'inverse : Map vers Mono<String> (note : Flux<String> en lecture pour \u00e9pargner du travail aux formats qui utilisent les sauts de lignes) vers fichier. Une classe AsyncFile dans le package infrastructure permet de lire les fichiers de mani\u00e8re asynchrone en produisant des flux Reactor. Remarque. Les MapEncoder sont tr\u00e8s simples : ils ne font que de l'encodage et du d\u00e9codage entre flux de cha\u00eenes et dictionnaire. En particulier, ils ne doivent pas d\u00e9crire plus pr\u00e9cisemment le processus de d\u00e9codage, et ne savent donc pas d\u00e9coder des fragments de fichiers . Il faut donc lire deux versions distinctes des fichiers, et (re)faire le diff au besoin sur les dictionnaires. Plus pr\u00e9cisemment, la lecture se fait ainsi : lecture de notre version : s'il y a des conflits, on lit nos lignes (strictement) + les lignes en commun; sinon on lit juste notre fichier lecture de leur patch : on lit leurs lignes (strictement), en retirant ce qui est r\u00e9solu En r\u00e9sum\u00e9 : Interpr\u00e9tation des drapeaux dans le cas de Git La lecture se passe ainsi : on lit le fichier, en mappant chaque ligne vers un ConflictMark . { \"foo\": \"bar\", <<<<<<< ... \"conflict\": \"v1\", ======= \"conflict\": \"v2\", >>>>>>> } Devient : ConflictMark.NONE ConflictMark.NONE ConflictMark.START ConflictMark.NONE ConflictMark.SPLIT ConflictMark.NONE ConflictMark.END ConflictMark.NONE Puis on r\u00e9p\u00e8te la marque pr\u00e9c\u00e9dente quand on a NONE . ConflictMark.NONE ConflictMark.NONE ConflictMark.START ConflictMark.START ConflictMark.SPLIT ConflictMark.SPLIT ConflictMark.END ConflictMark.END Ainsi, la lecture avec drapeau StrictlyOurs correspond au lignes mapp\u00e9es vers START , StrictlyTheirs \u00e0 celles mapp\u00e9es vers SPLIT . Le drapeau Resolved correspond pour sa part aux lignes mapp\u00e9es vers END ou NONE , ou \u00e0 la lecture simple d'un fichier de r\u00e9solution s'il existe. Synchronisation dans le cas de Git","title":"Documentation technique"},{"location":"doc_tech/#architecture-logique","text":"L'API utilise Mongo pour stocker des m\u00e9tadonn\u00e9es uniquement. Les vraies donn\u00e9es sont lues \u00e0 partir de repo clon\u00e9s via l'app. L'API interragit avec Git, mais d'autres VCS devraient pouvoir \u00eatre impl\u00e9ment\u00e9.","title":"Architecture logique"},{"location":"doc_tech/#concepts","text":"C\u00f4t\u00e9 base de donn\u00e9es, on ne garde que les m\u00e9tadonn\u00e9es des Project/Keyset/Key. Les objects Project , Keyset et Key sont fournis en r\u00e9ponse par l'API Rest (cf Swagger). { \"state\": \"Conflict\", \"translations\": { \"FR\": [ \"Annuler\" ], \"DE\": [ \"stornieren\" ], \"ES\": [ \"Anular\" ], \"EN\": [ \"Cancel\", \"Something else\" ] } } Une Key est la donn\u00e9e d'un \u00e9tat de cl\u00e9 (\u00e0 traduire = TODO , traduction demand\u00e9e = INPROGRESS ...) et de traductions (correspondance langue et liste de cha\u00eenes \u2013 la liste comporte une valeur en cas g\u00e9n\u00e9ral, et deux quand un conflit survient). Un Keyset agr\u00e8ge un ensemble de cl\u00e9 ensemble, et fournit quelques donn\u00e9es suppl\u00e9mentaires (nom, id, langages pris en compte...). Finalement, un Project agr\u00e8ge divers Keyset . C\u00f4t\u00e9 repr\u00e9sentation interne, ProjectMetadata et KeysetMetadata permettent de reconstruire les entit\u00e9s correspondantes. Le KeysetMetadata donne les chemins des fichiers de traduction qui contiennent les cl\u00e9s d'un Keyset . Par exemple, un fichier va contenir les traductions en anglais et un autre les traductions en allemand, et ce pour les m\u00eames cl\u00e9s techniques. Les exports sont g\u00e9r\u00e9s via deux entit\u00e9s. L'entit\u00e9 ExportDetails contient l'export CSV ainsi que des m\u00e9tadonn\u00e9es (sauv\u00e9es en base) qui permettent de retrouver l'export. Il faut en effet conserver des infos sur l'export (d'o\u00f9 KeySpec notamment qui redonne le \"chemin\" complet vers une cl\u00e9: projet, keyset, identifiant) car l'export ne contient que du texte brute, aucune m\u00e9tadonn\u00e9e.","title":"Concepts"},{"location":"doc_tech/#lecture-et-ecriture-de-fichiers-avec-gestion-de-conflits","text":"Remarque. Ici, on utilise le vocabulaire git ou presque, mais l'abstraction devrait pouvoir s'appliquer \u00e0 d'autres syst\u00e8mes de versionnement. Les \u00e9tapes pour la lecture : (g\u00e9r\u00e9 par FileHandler ) lecture des lignes (fichier \u2192 Flux<String> ) : assur\u00e9 par ConflictingFileHandle ; un drapeau ( ConflictFlag ) indique si l'on veut lire nos lignes ( ConflictFlag.StrictlyOurs ) ou les lignes upstream s'il y a des conflits ( ConflictFlag.StrictlyTheirs ), ou encore les lignes en commun ( ConflictFlag.Solved ), null peut \u00eatre utilis\u00e9 au lieu d'un drapeau s'il n'y a pas de conflit; traduction en dictionnaire ( Flux<String> \u2192 Map<String, String> ) : un MapEncoder \"adapt\u00e9\" (crit\u00e8re : extension du fichier) traduit le flux de lignes en dictionnaire (impl\u00e9ment\u00e9 : json, properties); adaptation : op\u00e9ration de diff au niveau des Maps selon que l'on veuille lire la version upstream ou la notre, d\u00e9tails ci dessous; conversion en Keyset : utilisation de Keyset.fromMaps pour obtenir une entit\u00e9 du domaine pour traitement fonctionnel. Pour l'\u00e9criture, c'est l'inverse : Map vers Mono<String> (note : Flux<String> en lecture pour \u00e9pargner du travail aux formats qui utilisent les sauts de lignes) vers fichier. Une classe AsyncFile dans le package infrastructure permet de lire les fichiers de mani\u00e8re asynchrone en produisant des flux Reactor. Remarque. Les MapEncoder sont tr\u00e8s simples : ils ne font que de l'encodage et du d\u00e9codage entre flux de cha\u00eenes et dictionnaire. En particulier, ils ne doivent pas d\u00e9crire plus pr\u00e9cisemment le processus de d\u00e9codage, et ne savent donc pas d\u00e9coder des fragments de fichiers . Il faut donc lire deux versions distinctes des fichiers, et (re)faire le diff au besoin sur les dictionnaires. Plus pr\u00e9cisemment, la lecture se fait ainsi : lecture de notre version : s'il y a des conflits, on lit nos lignes (strictement) + les lignes en commun; sinon on lit juste notre fichier lecture de leur patch : on lit leurs lignes (strictement), en retirant ce qui est r\u00e9solu En r\u00e9sum\u00e9 :","title":"Lecture et \u00e9criture de fichiers avec gestion de conflits"},{"location":"doc_tech/#interpretation-des-drapeaux-dans-le-cas-de-git","text":"La lecture se passe ainsi : on lit le fichier, en mappant chaque ligne vers un ConflictMark . { \"foo\": \"bar\", <<<<<<< ... \"conflict\": \"v1\", ======= \"conflict\": \"v2\", >>>>>>> } Devient : ConflictMark.NONE ConflictMark.NONE ConflictMark.START ConflictMark.NONE ConflictMark.SPLIT ConflictMark.NONE ConflictMark.END ConflictMark.NONE Puis on r\u00e9p\u00e8te la marque pr\u00e9c\u00e9dente quand on a NONE . ConflictMark.NONE ConflictMark.NONE ConflictMark.START ConflictMark.START ConflictMark.SPLIT ConflictMark.SPLIT ConflictMark.END ConflictMark.END Ainsi, la lecture avec drapeau StrictlyOurs correspond au lignes mapp\u00e9es vers START , StrictlyTheirs \u00e0 celles mapp\u00e9es vers SPLIT . Le drapeau Resolved correspond pour sa part aux lignes mapp\u00e9es vers END ou NONE , ou \u00e0 la lecture simple d'un fichier de r\u00e9solution s'il existe.","title":"Interpr\u00e9tation des drapeaux dans le cas de Git"},{"location":"doc_tech/#synchronisation-dans-le-cas-de-git","text":"","title":"Synchronisation dans le cas de Git"}]}